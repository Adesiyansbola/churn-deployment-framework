{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7bd35cf-e98a-4a98-bdd5-fc141c729fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic customer data...\n",
      "Final churn rate: 25.00%\n",
      "Synthetic data generation complete!\n",
      "Dataset saved to 'synthetic_churn_data.csv'.\n",
      "Dataset shape: (10000, 12)\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "   customer_id  tenure  age  support_calls subscription_type country  \\\n",
      "0            1      52   75              0             Basic      UK   \n",
      "1            2      15   37              1           Premium  France   \n",
      "2            3      61   53              1        Enterprise      UK   \n",
      "3            4      21   65              0             Basic  France   \n",
      "4            5      24   21              0           Premium      UK   \n",
      "\n",
      "   monthly_usage  avg_session_duration  feature_1_usage  feature_2_usage  \\\n",
      "0      32.374618             16.473425         1.157110         6.040795   \n",
      "1      19.353461             31.269014         2.707515         1.549471   \n",
      "2      30.092976             78.577621         4.528766        12.918040   \n",
      "3      32.243516             10.020259         0.949944         0.051125   \n",
      "4      20.240402             30.901430         0.383702         2.025493   \n",
      "\n",
      "   churn  usage_intensity  \n",
      "0      0         0.622589  \n",
      "1      0         1.290231  \n",
      "2      0         0.493327  \n",
      "3      0         1.535406  \n",
      "4      0         0.843350  \n"
     ]
    }
   ],
   "source": [
    "# data_simulation.py\n",
    "\"\"\"\n",
    "Script to generate a synthetic customer churn dataset for proof-of-concept.\n",
    "This dataset mimics web analytics and CRM data for a subscription-based business.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the number of samples\n",
    "n_samples = 10000\n",
    "\n",
    "print(\"Generating synthetic customer data...\")\n",
    "\n",
    "# 1. Generate basic customer demographics and static features\n",
    "df = pd.DataFrame({\n",
    "    'customer_id': range(1, n_samples + 1),\n",
    "    'tenure': np.random.randint(1, 72, n_samples),  # tenure in months (1-72 months)\n",
    "    'age': np.random.normal(45, 15, n_samples).astype(int),  # customer age\n",
    "    'support_calls': np.random.poisson(0.5, n_samples),  # number of support calls\n",
    "    'subscription_type': np.random.choice(['Basic', 'Premium', 'Enterprise'], n_samples, p=[0.6, 0.3, 0.1]),\n",
    "    'country': np.random.choice(['USA', 'UK', 'Germany', 'France', 'India'], n_samples, p=[0.5, 0.2, 0.1, 0.1, 0.1])\n",
    "})\n",
    "\n",
    "# 2. Generate behavioral features (Web Analytics Metrics)\n",
    "# These features are designed to be predictive of churn\n",
    "df['monthly_usage'] = np.random.normal(15, 5, n_samples)  # average sessions per month\n",
    "df['avg_session_duration'] = np.random.gamma(5, 5, n_samples)  # in minutes\n",
    "df['feature_1_usage'] = np.random.exponential(2, n_samples)\n",
    "df['feature_2_usage'] = np.random.exponential(3, n_samples)\n",
    "\n",
    "# 3. Introduce correlations: Make behavior depend on tenure and subscription type\n",
    "df['monthly_usage'] = df['monthly_usage'] * (1 + 0.02 * df['tenure'])  # usage increases with tenure\n",
    "df['avg_session_duration'] = df['avg_session_duration'] * (1 + 0.01 * df['tenure'])  # session duration increases with tenure\n",
    "\n",
    "# Premium users use more features\n",
    "df.loc[df['subscription_type'] == 'Premium', 'feature_1_usage'] *= 1.5\n",
    "df.loc[df['subscription_type'] == 'Enterprise', 'feature_1_usage'] *= 2.0\n",
    "df.loc[df['subscription_type'] == 'Premium', 'feature_2_usage'] *= 1.3\n",
    "df.loc[df['subscription_type'] == 'Enterprise', 'feature_2_usage'] *= 1.8\n",
    "\n",
    "# 4. Create a target variable 'churn' based on a logical function of the features\n",
    "# We create a \"risk_score\" that is a linear combination of features\n",
    "risk_score = (\n",
    "    -0.1 * df['tenure']  # Higher tenure -> lower risk\n",
    "    + 0.05 * df['age']  # Slight increase with age\n",
    "    + 0.8 * df['support_calls']  # More support calls -> much higher risk\n",
    "    - 0.5 * df['monthly_usage']  # Higher usage -> lower risk\n",
    "    - 0.3 * df['avg_session_duration']  # Longer sessions -> lower risk\n",
    "    - 0.2 * df['feature_1_usage']  # More feature use -> lower risk\n",
    "    - 0.2 * df['feature_2_usage']  # More feature use -> lower risk\n",
    "    + np.random.normal(0, 1, n_samples)  # Add some randomness\n",
    ")\n",
    "\n",
    "# Convert the risk_score to a probability using the logistic function\n",
    "churn_probability = 1 / (1 + np.exp(-risk_score))\n",
    "\n",
    "# Generate binary churn labels (0/1) based on the probability\n",
    "df['churn'] = np.random.binomial(1, churn_probability)\n",
    "\n",
    "# Ensure a minimum number of churners for the class imbalance (roughly 20%)\n",
    "# This is a common ratio in churn datasets\n",
    "if df['churn'].mean() < 0.15:\n",
    "    adjustment = risk_score > np.percentile(risk_score, 75)\n",
    "    df.loc[adjustment, 'churn'] = 1\n",
    "elif df['churn'].mean() > 0.35:\n",
    "    adjustment = risk_score < np.percentile(risk_score, 25)\n",
    "    df.loc[adjustment, 'churn'] = 0\n",
    "\n",
    "print(f\"Final churn rate: {df['churn'].mean():.2%}\")\n",
    "\n",
    "# 5. Perform final feature engineering\n",
    "# Create a key predictive feature: usage intensity (usage per month of tenure)\n",
    "df['usage_intensity'] = df['monthly_usage'] / df['tenure'].clip(lower=1)  # Avoid division by zero\n",
    "\n",
    "# 6. Save the synthetic dataset to a CSV file\n",
    "output_file = 'synthetic_churn_data.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Synthetic data generation complete!\")\n",
    "print(f\"Dataset saved to '{output_file}'.\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b81800-c516-4bc7-b7f0-7e7082305830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
